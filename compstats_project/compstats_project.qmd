---
title: "The No-U-Turn-Sampler"
subtitle: "Computational Statistics Project"
author: 
- "Jonathan Fitter ([jfitter@wu.ac.at](mailto:jonathan.fitter@wu.ac.at))"
- "Max Heinze ([mheinze@wu.ac.at](mailto:mheinze@wu.ac.at))"
institute:
- "Department of Economics, Vienna University of Economics and Business (WU Vienna)"
date: "2025-05-27"
date-format: long
lang: en
format: 
  revealjs:
    theme: [default, ../style/mhslides_flippedcols.css]
    width: 1280
    height: 720
    margin: 0
    progress: false
    overview: false
    highlight-style: github
    slideNumber: true
    html-math-method: mathjax
    embed-resources: true
    pdfMaxPagesPerSlide: 1
    pdfSeparateFragments: false
    template-partials:
      - ../style/title-slide.html
    filters:
      - ../style/section-header.lua
      - _filters/pdf-to-svg.lua
      - _filters/space.lua
      - quarto-kroki
      - _filters/svgfonts.lua
engine: knitr
bibliography: references.bib
csl: ../style/apa.csl
nocite: |
  @hoffman2014
---

# Intro and Recap

## Markov Chain

. . . 

A [**Markov chain**]{.col1} is a stochastic process $\{X_t\}$ indexed by time $t\geq 0$.

:::{.incremental}
* We call the **set of all values** that $\{X_t\}$ can assume the [**state space**]{.col1} of the Markov Chain.
* $\{X-t\}$ is called a Markov Chain if it fulfills the [**Markov property**]{.col1} that
  $$
  P(X_{t+1}=j\mid X_0=i_0,\dots,X_t=i_t)=P(X_{t+1}=j\mid X_t=i_t),
  $$
  i.e., that the conditional distribution of the next state depends only on the current state.
:::

. . .

[**Markov Chain Monte Carlo (MCMC)**]{.col1} methods make use of Markov chains to sample from a **target distribution**. 

## Markov Chain

::::{.columns}
:::{.column width="40%" .fragment}
::: {.w100 .centering}
```{kroki-tikz}
\documentclass{standalone}
\usepackage{tikz}
\usepackage{amsmath}
\usetikzlibrary{automata,positioning,arrows.meta}

\begin{document}
\begin{tikzpicture}[->,>=Stealth,shorten >=1pt,auto,node distance=3cm,semithick]
  \node[state] (A) {$A$};
  \node[state] (B) [right of=A] {$B$};
  \node[state] (C) [below of=A] {$C$};

  \path
    (A) edge [loop above] node {0.5} ()
        edge              node {0.3} (B)
        edge [bend left]  node {0.2} (C)
    (B) edge [loop above] node {0.6} ()
        edge [bend left]  node {0.4} (C)
    (C) edge [loop below] node {0.7} ()
        edge [bend left]  node {0.3} (A);
\end{tikzpicture}
\end{document}
```
:::
:::
:::{.column width="60%" .fragment}
Markov chains are

:::{.incremental}
* **irreducible**, i.e. every state can eventually be reached from any state;
* **aperiodic**, i.e. reverting to a state is not only possible after a multiple of a certain number of steps;
* **positive recurrent**, i.e. for all states, the expected number of transitions to return to that state is finite.
:::

[For such Markov Chains, [**transition probabilities**]{.col1} converge to a unique stationary distribution on the state space.]{.fragment}

:::
::::

## Metropolis-Hastings

::::{.columns}
:::{.column width="40%" .fragment}

:vspace2

::: {.w100 .centering}
```{kroki-tikz}
\documentclass{standalone}
\usepackage{tikz}
\usetikzlibrary{automata,arrows,positioning}
\begin{document}
\begin{tikzpicture}[->,>=stealth',shorten >=1pt,node distance=3cm]
  \node[state] (i) {$i$};
  \node[state] (j) [right=of i] {$j$};
  \node[state] (k) [below=of i] {$k$};
  \path
    (i) edge[bend left] node[above] {$g(j\mid i)\,\alpha(i,j)$} (j)
        edge[loop above]  node           {$1-\sum_{h\neq i}g(h\mid i)\,\alpha(i,h)$} ()
    (j) edge[bend left] node[below] {$g(i\mid j)\,\alpha(j,i)$} (i)
        edge[bend left] node[above] {$g(k\mid j)\,\alpha(j,k)$} (k)
    (k) edge[bend left] node[below] {$g(i\mid k)\,\alpha(k,i)$} (i)
        edge[loop below]  node           {$1-\sum_{h\neq k}g(h\mid k)\,\alpha(k,h)$} ();
\end{tikzpicture}
\end{document}
```
:::
:::
:::{.column width="60%" .fragment}

**Metropolis-Hastings** is a class of MCMC methods. 

:::{.incremental}
*	Propose $Y\sim g(\cdot\mid X_t)$, compute $\alpha(i,j)=\min\Bigl(1,\frac{f(j)\,g(i\mid j)}{f(i)\,g(j\mid i)}\Bigr)$.
* If $U\le\alpha(i,j)$, move $i\to j$; else stay at $i$.
* Chain is reversible and has $f$ as its stationary distribution.
:::



:::
::::




# Hamiltonian Monte Carlo

## Origins in Physics

::::{.columns}
:::{.column width="45%" .fragment .centering}

:vspace3

![](figures/puck.svg){width=100%}
:::
:::{.column width="55%" .fragment}

Imagine a **frictionless puck** on a **non-even surface**. The [**state of this system**]{.col1} is given by

:::{.incremental}
*	$\boldsymbol{q}$, the [**position**]{.col1} of the puck;
* $\boldsymbol{p}$, the [**momentum**]{.col2} of the puck, given by $\mathrm{mass}\times\mathrm{velocity}$.
* If the puck encounters a **rising slope**, momentum will decrease; if it encounters a **falling slope**, momentum will increase.
* The higher the surface at a position, the higher the puck's **potential energy**, and the lower its **kinetic energy**.
:::



:::
::::

## From Physics to Statistics

In **non-physical** applications, 

:::{.incremental}
* the [**position**]{.col1} $\boldsymbol{q}$ corresponds to the [**variables of interest**]{.col1}
* the [**momentum**]{.col2} $\boldsymbol{p}$ corresponds to the [**negative log of the probability density**]{.col2} for these variables.
:::

## Hamiltonian Dynamics

```{=html}
<iframe src="https://chi-feng.github.io/mcmc-demo/app.html" width="1200" height="600" style="border: none;"></iframe>
```

@neal2012

## Text

## Slide Title

:::{.incremental}
* This
* is
* some
* text.
:::


# The No-U-Turn-Sampler (NUTS)

## Slide Title

:::{.incremental}
* This
* is
* some
* text.
:::

# Empirical Stuff

## Slide Title

:::{.incremental}
* This
* is
* some
* text.
:::



## References 

:::{.centering .titlebox1}
_This list is **scrollable**._
:::

::: {#refs}
:::






